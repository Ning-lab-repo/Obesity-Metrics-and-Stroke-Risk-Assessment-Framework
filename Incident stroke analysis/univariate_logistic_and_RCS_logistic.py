import os
threads_per_task = 6
os.environ["OMP_NUM_THREADS"] = str(threads_per_task)
os.environ["OPENBLAS_NUM_THREADS"] = str(threads_per_task)
os.environ["MKL_NUM_THREADS"] = str(threads_per_task)
os.environ["VECLIB_MAXIMUM_THREADS"] = str(threads_per_task)
os.environ["NUMEXPR_NUM_THREADS"] = str(threads_per_task)

import pandas as pd
import numpy as np
from statsmodels.api import Logit, add_constant
from statsmodels.stats.multitest import fdrcorrection
from patsy import dmatrix
import scipy.stats as stats
import warnings
from statsmodels.tools.sm_exceptions import ConvergenceWarning
warnings.filterwarnings('ignore')
from sklearn.preprocessing import StandardScaler
# ===============================
# 1. Read data
# ===============================
var_file = "/3839.csv"
var_data = pd.read_csv(var_file)

# 2. Uniformly convert empty strings to NaN
df = var_data.applymap(
    lambda x: np.nan if isinstance(x, str) and x.strip() == "" else x
)

# ===============================
# 3. Define variables
# ===============================
main_vars = [
    'BMI', 'WHR', 'Height', 'Weight', 'WC', 'HC',
    'WHtR', 'HHtR', 'ABSI', 'BRI', 'BF_percent'
]

covariates = ['age', 'sex']
outcomes = ["subject",'Ischemic_Stroke', 'Hemorrhagic_Stroke']

# Ensure that the outcome variable is numerical
for col in outcomes:
    df[col] = pd.to_numeric(df[col], errors='coerce')

# ===============================
# 4. Univariate Logistic Regression Function
# ===============================
def run_univariate_logistic(data, var, outcome, adjust_vars):
    """
    å•å˜é‡Logisticå›å½’ï¼ˆè°ƒæ•´åå˜é‡ï¼‰
    """
    cols = [outcome, var] + adjust_vars
    
    # æ•°å€¼åŒ–å¹¶åˆ é™¤ç¼ºå¤±
    df_model = data[cols].apply(pd.to_numeric, errors='coerce').dropna()
    
    if df_model.shape[0] < 50:
        return None
    
    if df_model[outcome].nunique() < 2:
        return None
    scaler = StandardScaler()
    fei_cvar = ["sex","Smoke","Alcohol","Summed_minutes_activity","HTNhis","CHDhis","RENhis","hyperlipid","DM","hypertension","spirin","antihyper"]
    ac_vars = [v for v in adjust_vars if v not in fei_cvar]
    b_cols = [var]+ac_vars
    df_model[b_cols] = scaler.fit_transform(df_model[b_cols])
    try:
        # å‡†å¤‡æ•°æ®
        X = df_model[[var] + adjust_vars]
        X = add_constant(X)
        y = df_model[outcome]
        
        # æ‹Ÿåˆæ¨¡å‹
        model = Logit(y, X).fit(disp=False, maxiter=300)
        
        # æå–ä¸»å˜é‡çš„ç»“æœ
        coef = model.params[var]
        se = model.bse[var]
        pval = model.pvalues[var]
        
        or_value = np.exp(coef)
        or_lci = np.exp(coef - 1.96 * se)
        or_uci = np.exp(coef + 1.96 * se)
        
        return {
            'variable': var,
            'outcome': outcome,
            'n': df_model.shape[0],
            'events': int(y.sum()),
            'OR': or_value,
            'OR_LCI': or_lci,
            'OR_UCI': or_uci,
            'p_value': pval,
            'coef': coef,
            'se': se
        }
    except Exception as e:
        print(f"  âœ— {var} - {outcome} LRå¤±è´¥: {e}")
        return None

# ===============================
# 5. RCS analysis function
# ===============================
def run_logistic_rcs(data, var, outcome, adjust_vars, knots=4):
    """
    Logistic RCSåˆ†æ
    """
    cols = [outcome, var] + adjust_vars
    
    # æ•°å€¼åŒ–å¹¶åˆ é™¤ç¼ºå¤±
    df_model = data[cols].apply(pd.to_numeric, errors='coerce').dropna()
    
    if df_model.shape[0] < 100:
        return None
    
    if df_model[outcome].nunique() < 2:
        return None
    
    try:
        # ç”ŸæˆRCSåŸºå‡½æ•°
        formula = f"cr({var}, df={knots-1})"
        spline_basis = dmatrix(formula, df_model, return_type="dataframe")
        
        # å‡†å¤‡åå˜é‡
        X = pd.concat([spline_basis, df_model[adjust_vars]], axis=1)
        X = add_constant(X)
        y = df_model[outcome]
        
        # æ‹Ÿåˆæ¨¡å‹
        model = Logit(y, X).fit(disp=False, maxiter=300)
        
        # éçº¿æ€§æ£€éªŒï¼ˆWald testï¼‰
        spline_cols = [c for c in spline_basis.columns if 'Intercept' not in c]
        beta = model.params[spline_cols]
        cov = model.cov_params().loc[spline_cols, spline_cols]
        wald_chi2 = float(beta.T @ np.linalg.inv(cov) @ beta)
        p_nonlinear = 1 - stats.chi2.cdf(wald_chi2, len(beta))
        
        # ç”Ÿæˆç»˜å›¾æ•°æ®
        test_range = np.linspace(
            df_model[var].quantile(0.05), 
            df_model[var].quantile(0.95), 
            100
        )
        
        # å‚ç…§ç‚¹ï¼šä¸­ä½æ•°
        ref_val = df_model[var].median()
        
        # æ„å»ºé¢„æµ‹æ•°æ®
        plot_df = pd.DataFrame({var: np.append(test_range, ref_val)})
        for cov_var in adjust_vars:
            if df_model[cov_var].nunique() == 2:  # äºŒåˆ†ç±»å˜é‡ç”¨ä¼—æ•°
                plot_df[cov_var] = df_model[cov_var].mode()[0]
            else:  # è¿ç»­å˜é‡ç”¨å‡å€¼
                plot_df[cov_var] = df_model[cov_var].mean()
        
        # è®¡ç®—é¢„æµ‹çŸ©é˜µ
        X_plot_basis = dmatrix(formula, plot_df, return_type="dataframe")
        X_plot = pd.concat([X_plot_basis, plot_df[adjust_vars]], axis=1)
        X_plot = add_constant(X_plot)
        
        # è®¡ç®—Log-OddsåŠå…¶æ ‡å‡†è¯¯
        predictions = np.dot(X_plot, model.params)
        cov_mat = model.cov_params().values
        se_predictions = np.sqrt(np.diag(X_plot.values @ cov_mat @ X_plot.values.T))
        
        # ç›¸å¯¹äºå‚ç…§ç‚¹çš„OR
        ref_log_odds = predictions[-1]
        
        res_plot = pd.DataFrame({
            "value": test_range,
            "OR": np.exp(predictions[:-1] - ref_log_odds),
            "OR_lower": np.exp((predictions[:-1] - ref_log_odds) - 1.96 * se_predictions[:-1]),
            "OR_upper": np.exp((predictions[:-1] - ref_log_odds) + 1.96 * se_predictions[:-1]),
            "log_OR": predictions[:-1] - ref_log_odds,
            "se_log_OR": se_predictions[:-1]
        })
        
        return {
            "summary": {
                "variable": var,
                "outcome": outcome,
                "n": df_model.shape[0],
                "events": int(y.sum()),
                "reference_value": ref_val,
                "p_nonlinear": p_nonlinear,
                "wald_chi2": wald_chi2,
                "df": len(beta)
            },
            "plot_data": res_plot
        }
    except Exception as e:
        print(f"  âœ— {var} - {outcome} RCSå¤±è´¥: {e}")
        return None

# ===============================
# 6. Main analysis workflow
# ===============================

lr_results = []

for outcome in outcomes:
    print(f"\nåˆ†æç»“å±€: {outcome}")
    print(f"  äº‹ä»¶æ•°: {df[outcome].sum()}")
    
    for var in main_vars:
        if var not in df.columns:
            print(f"  âš ï¸ å˜é‡ä¸å­˜åœ¨: {var}")
            continue
        
        result = run_univariate_logistic(df, var, outcome, covariates)
        
        if result:
            lr_results.append(result)
            print(f"  âœ“ {var}: OR={result['OR']:.3f} ({result['OR_LCI']:.3f}-{result['OR_UCI']:.3f}), p={result['p_value']:.4f}")

if lr_results:
    lr_df = pd.DataFrame(lr_results)
    
    # FDRæ ¡æ­£ï¼ˆæŒ‰ç»“å±€åˆ†ç»„ï¼‰
    for outcome in outcomes:
        mask = lr_df['outcome'] == outcome
        if mask.sum() > 0:
            _, padj = fdrcorrection(lr_df.loc[mask, 'p_value'].values)
            lr_df.loc[mask, 'p_adj'] = padj
    
    # ä¿å­˜
    lr_output = "/home/data/wangshikai/è„‘å’ä¸­/LR/Univariate_LR_Results.csv"
    os.makedirs(os.path.dirname(lr_output), exist_ok=True)
    lr_df.to_csv(lr_output, index=False)
    print(f"\nâœ… å•å˜é‡LRç»“æœå·²ä¿å­˜: {lr_output}")
    print(f"   å…±{len(lr_results)}ä¸ªæœ‰æ•ˆåˆ†æ")

# ===============================
# 7. RCS analysis
# ===============================

rcs_summaries = []
output_dir = "/LR/RCS"
os.makedirs(output_dir, exist_ok=True)

for outcome in outcomes:
    print(f"\nåˆ†æç»“å±€: {outcome}")
    
    for var in main_vars:
        if var not in df.columns:
            continue
        
        result = run_logistic_rcs(df, var, outcome, covariates, knots=4)
        
        if result:
            rcs_summaries.append(result["summary"])
            
            # ä¿å­˜æ›²çº¿æ•°æ®
            safe_var_name = var.replace("/", "_per_")
            plot_file = f"{output_dir}/RCS_{outcome}_{safe_var_name}.csv"
            result["plot_data"].to_csv(plot_file, index=False)
            
            print(f"  âœ“ {var}: p_nonlinear={result['summary']['p_nonlinear']:.4f}, ref={result['summary']['reference_value']:.2f}")

if rcs_summaries:
    rcs_df = pd.DataFrame(rcs_summaries)
    
    # FDRæ ¡æ­£
    for outcome in outcomes:
        mask = rcs_df['outcome'] == outcome
        if mask.sum() > 0:
            _, padj = fdrcorrection(rcs_df.loc[mask, 'p_nonlinear'].values)
            rcs_df.loc[mask, 'p_adj'] = padj
    
    # ä¿å­˜
    rcs_summary_file = "/home/data/wangshikai/è„‘å’ä¸­/LR/RCS_Summary_Table.csv"
    rcs_df.to_csv(rcs_summary_file, index=False)
    print(f"\nâœ… RCSæ±‡æ€»ç»“æœå·²ä¿å­˜: {rcs_summary_file}")
    print(f"   å…±{len(rcs_summaries)}ä¸ªæœ‰æ•ˆåˆ†æ")
    print(f"ğŸ“ˆ RCSæ›²çº¿æ•°æ®ä¿å­˜ç›®å½•: {output_dir}")

# ===============================
# 8. Generate a comprehensive report
# ===============================


if lr_results and rcs_summaries:
    for outcome in outcomes:
        lr_count = sum(1 for r in lr_results if r['outcome'] == outcome)
        rcs_count = sum(1 for r in rcs_summaries if r['outcome'] == outcome)
        
        print(f"\n{outcome}:")
        print(f"  - å•å˜é‡LR: {lr_count}ä¸ªå˜é‡")
        print(f"  - RCSåˆ†æ: {rcs_count}ä¸ªå˜é‡")
        
        # æ˜¾è‘—ç»“æœç»Ÿè®¡
        if lr_count > 0:
            sig_lr = lr_df[(lr_df['outcome'] == outcome) & (lr_df['p_value'] < 0.05)]
            print(f"  - LRæ˜¾è‘—å˜é‡ (p<0.05): {len(sig_lr)}ä¸ª")
            if len(sig_lr) > 0:
                print(f"    {', '.join(sig_lr['variable'].tolist())}")
        
        if rcs_count > 0:
            sig_rcs = rcs_df[(rcs_df['outcome'] == outcome) & (rcs_df['p_nonlinear'] < 0.05)]
            print(f"  - RCSéçº¿æ€§æ˜¾è‘— (p<0.05): {len(sig_rcs)}ä¸ª")
            if len(sig_rcs) > 0:
                print(f"    {', '.join(sig_rcs['variable'].tolist())}")

print("\n" + "=" * 80)
print("All analyses completedï¼")
print("=" * 80)